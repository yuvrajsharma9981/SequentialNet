# SequentialNet

![Status](https://img.shields.io/badge/status-under%20construction-yellow)
![License](https://img.shields.io/badge/license-MIT-blue)

## Overview

`SequentialNet` is an evolving library that aims to encapsulate the evolutionary journey of neural network architectures focusing primarily on sequence modeling tasks. This library will serve as a hub where enthusiasts and practitioners can explore the progression of neural network architectures, right from Multi-Layer Perceptrons (MLP) to advanced architectures like Transformers.

## Project Structure

The project is structured to illustrate the progression in the complexity and capabilities of various neural network architectures. It intends to offer implementations of the following:

1. **Multi-Layer Perceptrons (MLP)**: The foundational neural network model.
2. **Recurrent Neural Networks (RNN)**: Introducing sequence modeling.
3. **Long Short-Term Memory (LSTM)**: A more advanced sequence modeling architecture.
4. **Transformers**: The state-of-the-art architectures for a variety of tasks, including both autoencoding and autoregressive structures.

As the library develops, it will not only serve as a toolkit but also as an educational resource, illustrating the evolution of sequence modeling architectures in neural networks.

## Getting Started (Under Construction)

Documentation on how to get started with `SequentialNet` will be available soon.

## Contribution

We welcome contributions! If you are interested in enhancing the functionalities or adding new features, please feel free to create a pull request.

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for more details.

## Contact

For any queries or discussions, feel free to open an issue.

---

:construction: The library is currently under construction. Stay tuned for more updates! :construction:
